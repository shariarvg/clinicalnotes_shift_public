
A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/users/sv226/everything/clinicalnotes_shift/bashfiles/../pythonscripts/all_attacks_script.py", line 4, in <module>
    from attack_tools import *
  File "/home/users/sv226/everything/clinicalnotes_shift/pythontools/attack_tools.py", line 1, in <module>
    import pandas as pd
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/api.py", line 28, in <module>
    from pandas.core.arrays import Categorical
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/arrays/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/arrays/arrow/__init__.py", line 5, in <module>
    from pandas.core.arrays.arrow.array import ArrowExtensionArray
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/arrays/arrow/array.py", line 50, in <module>
    from pandas.core import (
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/ops/__init__.py", line 8, in <module>
    from pandas.core.ops.array_ops import (
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/ops/array_ops.py", line 56, in <module>
    from pandas.core.computation import expressions
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/computation/expressions.py", line 21, in <module>
    from pandas.core.computation.check import NUMEXPR_INSTALLED
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/computation/check.py", line 5, in <module>
    ne = import_optional_dependency("numexpr", errors="warn")
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/compat/_optional.py", line 135, in import_optional_dependency
    module = importlib.import_module(name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/usr/lib/python3/dist-packages/numexpr/__init__.py", line 24, in <module>
    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__
AttributeError: _ARRAY_API not found

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/users/sv226/everything/clinicalnotes_shift/bashfiles/../pythonscripts/all_attacks_script.py", line 4, in <module>
    from attack_tools import *
  File "/home/users/sv226/everything/clinicalnotes_shift/pythontools/attack_tools.py", line 1, in <module>
    import pandas as pd
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/__init__.py", line 49, in <module>
    from pandas.core.api import (
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/api.py", line 28, in <module>
    from pandas.core.arrays import Categorical
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/arrays/__init__.py", line 1, in <module>
    from pandas.core.arrays.arrow import ArrowExtensionArray
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/arrays/arrow/__init__.py", line 5, in <module>
    from pandas.core.arrays.arrow.array import ArrowExtensionArray
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/arrays/arrow/array.py", line 64, in <module>
    from pandas.core.arrays.masked import BaseMaskedArray
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py", line 60, in <module>
    from pandas.core import (
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/core/nanops.py", line 52, in <module>
    bn = import_optional_dependency("bottleneck", errors="warn")
  File "/home/users/sv226/.local/lib/python3.10/site-packages/pandas/compat/_optional.py", line 135, in import_optional_dependency
    module = importlib.import_module(name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/usr/lib/python3/dist-packages/bottleneck/__init__.py", line 2, in <module>
    from .reduce import (
AttributeError: _ARRAY_API not found
2025-03-28 07:43:48.505824: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-03-28 07:43:48.518502: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1743162228.535258   50257 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1743162228.540461   50257 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1743162228.554892   50257 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1743162228.554921   50257 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1743162228.554927   50257 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1743162228.554932   50257 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-03-28 07:43:48.558945: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/users/sv226/everything/clinicalnotes_shift/bashfiles/../pythonscripts/all_attacks_script.py", line 4, in <module>
    from attack_tools import *
  File "/home/users/sv226/everything/clinicalnotes_shift/pythontools/attack_tools.py", line 6, in <module>
    import mmd_tools
  File "/home/users/sv226/everything/clinicalnotes_shift/pythontools/mmd_tools.py", line 20, in <module>
    from sentence_transformers import SentenceTransformer
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/__init__.py", line 14, in <module>
    from sentence_transformers.cross_encoder.CrossEncoder import CrossEncoder
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/__init__.py", line 3, in <module>
    from .CrossEncoder import CrossEncoder
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 18, in <module>
    from sentence_transformers.evaluation.SentenceEvaluator import SentenceEvaluator
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/evaluation/__init__.py", line 9, in <module>
    from .NanoBEIREvaluator import NanoBEIREvaluator
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/evaluation/NanoBEIREvaluator.py", line 11, in <module>
    from sentence_transformers import SentenceTransformer
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py", line 33, in <module>
    from sentence_transformers.model_card import SentenceTransformerModelCardData, generate_model_card
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/model_card.py", line 25, in <module>
    from transformers.integrations import CodeCarbonCallback
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1964, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1976, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/integrations/integration_utils.py", line 36, in <module>
    from .. import PreTrainedModel, TFPreTrainedModel
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1964, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1976, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/modeling_utils.py", line 61, in <module>
    from .loss.loss_utils import LOSS_MAPPING
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/loss/loss_utils.py", line 19, in <module>
    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/loss/loss_deformable_detr.py", line 4, in <module>
    from ..image_transforms import center_to_corners_format
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/image_transforms.py", line 48, in <module>
    import tensorflow as tf
  File "/home/users/sv226/.local/lib/python3.10/site-packages/tensorflow/__init__.py", line 468, in <module>
    importlib.import_module("keras.src.optimizers")
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/users/sv226/.local/lib/python3.10/site-packages/keras/__init__.py", line 2, in <module>
    from keras.api import DTypePolicy
  File "/home/users/sv226/.local/lib/python3.10/site-packages/keras/api/__init__.py", line 8, in <module>
    from keras.api import activations
  File "/home/users/sv226/.local/lib/python3.10/site-packages/keras/api/activations/__init__.py", line 7, in <module>
    from keras.src.activations import deserialize
  File "/home/users/sv226/.local/lib/python3.10/site-packages/keras/src/__init__.py", line 13, in <module>
    from keras.src import visualization
  File "/home/users/sv226/.local/lib/python3.10/site-packages/keras/src/visualization/__init__.py", line 2, in <module>
    from keras.src.visualization import plot_image_gallery
  File "/home/users/sv226/.local/lib/python3.10/site-packages/keras/src/visualization/plot_image_gallery.py", line 13, in <module>
    import matplotlib.pyplot as plt
  File "/usr/lib/python3/dist-packages/matplotlib/__init__.py", line 109, in <module>
    from . import _api, _version, cbook, docstring, rcsetup
  File "/usr/lib/python3/dist-packages/matplotlib/rcsetup.py", line 27, in <module>
    from matplotlib.colors import Colormap, is_color_like
  File "/usr/lib/python3/dist-packages/matplotlib/colors.py", line 56, in <module>
    from matplotlib import _api, cbook, scale
  File "/usr/lib/python3/dist-packages/matplotlib/scale.py", line 23, in <module>
    from matplotlib.ticker import (
  File "/usr/lib/python3/dist-packages/matplotlib/ticker.py", line 136, in <module>
    from matplotlib import transforms as mtransforms
  File "/usr/lib/python3/dist-packages/matplotlib/transforms.py", line 46, in <module>
    from matplotlib._path import (
AttributeError: _ARRAY_API not found

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.4 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/users/sv226/everything/clinicalnotes_shift/bashfiles/../pythonscripts/all_attacks_script.py", line 4, in <module>
    from attack_tools import *
  File "/home/users/sv226/everything/clinicalnotes_shift/pythontools/attack_tools.py", line 6, in <module>
    import mmd_tools
  File "/home/users/sv226/everything/clinicalnotes_shift/pythontools/mmd_tools.py", line 20, in <module>
    from sentence_transformers import SentenceTransformer
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/__init__.py", line 14, in <module>
    from sentence_transformers.cross_encoder.CrossEncoder import CrossEncoder
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/__init__.py", line 3, in <module>
    from .CrossEncoder import CrossEncoder
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py", line 18, in <module>
    from sentence_transformers.evaluation.SentenceEvaluator import SentenceEvaluator
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/evaluation/__init__.py", line 9, in <module>
    from .NanoBEIREvaluator import NanoBEIREvaluator
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/evaluation/NanoBEIREvaluator.py", line 11, in <module>
    from sentence_transformers import SentenceTransformer
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py", line 33, in <module>
    from sentence_transformers.model_card import SentenceTransformerModelCardData, generate_model_card
  File "/home/users/sv226/.local/lib/python3.10/site-packages/sentence_transformers/model_card.py", line 25, in <module>
    from transformers.integrations import CodeCarbonCallback
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1964, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1976, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/integrations/integration_utils.py", line 36, in <module>
    from .. import PreTrainedModel, TFPreTrainedModel
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1964, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1976, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/modeling_utils.py", line 61, in <module>
    from .loss.loss_utils import LOSS_MAPPING
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/loss/loss_utils.py", line 19, in <module>
    from .loss_deformable_detr import DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/loss/loss_deformable_detr.py", line 4, in <module>
    from ..image_transforms import center_to_corners_format
  File "/home/users/sv226/.local/lib/python3.10/site-packages/transformers/image_transforms.py", line 48, in <module>
    import tensorflow as tf
  File "/home/users/sv226/.local/lib/python3.10/site-packages/tensorflow/__init__.py", line 468, in <module>
    importlib.import_module("keras.src.optimizers")
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/home/users/sv226/.local/lib/python3.10/site-packages/keras/__init__.py", line 2, in <module>
    from keras.api import DTypePolicy
  File "/home/users/sv226/.local/lib/python3.10/site-packages/keras/api/__init__.py", line 34, in <module>
    from keras.api import visualization
  File "/home/users/sv226/.local/lib/python3.10/site-packages/keras/api/visualization/__init__.py", line 11, in <module>
    from keras.src.visualization.plot_bounding_box_gallery import (
  File "/home/users/sv226/.local/lib/python3.10/site-packages/keras/src/visualization/plot_bounding_box_gallery.py", line 12, in <module>
    from matplotlib import patches  # For legend patches
  File "/usr/lib/python3/dist-packages/matplotlib/__init__.py", line 109, in <module>
    from . import _api, _version, cbook, docstring, rcsetup
  File "/usr/lib/python3/dist-packages/matplotlib/rcsetup.py", line 27, in <module>
    from matplotlib.colors import Colormap, is_color_like
  File "/usr/lib/python3/dist-packages/matplotlib/colors.py", line 56, in <module>
    from matplotlib import _api, cbook, scale
  File "/usr/lib/python3/dist-packages/matplotlib/scale.py", line 23, in <module>
    from matplotlib.ticker import (
  File "/usr/lib/python3/dist-packages/matplotlib/ticker.py", line 136, in <module>
    from matplotlib import transforms as mtransforms
  File "/usr/lib/python3/dist-packages/matplotlib/transforms.py", line 46, in <module>
    from matplotlib._path import (
AttributeError: _ARRAY_API not found
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
/home/users/sv226/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
/home/users/sv226/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
/home/users/sv226/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
/home/users/sv226/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
/home/users/sv226/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
/home/users/sv226/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
/home/users/sv226/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
/home/users/sv226/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
/home/users/sv226/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
WARNING clustering 200 points to 10 centroids: please provide at least 390 training points
(200, 1024)
(160, 1024)
(40, 1024)
0
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.532632827758789 seconds
Average featurization time: 0.79
(200, 1024)
(160, 1024)
(40, 1024)
0
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.371721267700195 seconds
Average featurization time: 0.77
(200, 1024)
(160, 1024)
(40, 1024)
0
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.415005922317505 seconds
Average featurization time: 0.78
(200, 1024)
(160, 1024)
(40, 1024)
0
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.349583864212036 seconds
Average featurization time: 0.77
(200, 647)
(160, 647)
(40, 647)
0
(200, 591)
(160, 591)
(40, 591)
Experiment time: 2.322756767272949 seconds
Average featurization time: 0.03
(200, 50)
(160, 50)
(40, 50)
0
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.252668142318726 seconds
Average featurization time: 0.78
(200, 50)
(160, 50)
(40, 50)
0
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.282226800918579 seconds
Average featurization time: 0.79
(200, 1024)
(160, 1024)
(40, 1024)
0
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.413508653640747 seconds
Average featurization time: 0.79
(200, 1024)
(160, 1024)
(40, 1024)
0
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.378438234329224 seconds
Average featurization time: 0.77
(200, 1024)
(160, 1024)
(40, 1024)
0
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.752652883529663 seconds
Average featurization time: 0.78
(200, 1024)
(160, 1024)
(40, 1024)
0
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.4320995807647705 seconds
Average featurization time: 0.78
(200, 591)
(160, 591)
(40, 591)
0
(200, 545)
(160, 545)
(40, 545)
Experiment time: 2.273407220840454 seconds
Average featurization time: 0.03
(200, 50)
(160, 50)
(40, 50)
0
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.238833904266357 seconds
Average featurization time: 0.79
(200, 50)
(160, 50)
(40, 50)
0
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.291779279708862 seconds
Average featurization time: 0.79
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.04753851890564 seconds
Average featurization time: 0.77
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.000750303268433 seconds
Average featurization time: 0.77
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.091490268707275 seconds
Average featurization time: 0.77
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.11204981803894 seconds
Average featurization time: 0.77
(200, 545)
(160, 545)
(40, 545)
(200, 19)
(160, 19)
(40, 19)
Experiment time: 1.921823263168335 seconds
Average featurization time: 0.03
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 4.917659282684326 seconds
Average featurization time: 0.78
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 4.90343976020813 seconds
Average featurization time: 0.78
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.060700416564941 seconds
Average featurization time: 0.77
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.09528660774231 seconds
Average featurization time: 0.76
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.126791954040527 seconds
Average featurization time: 0.77
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.0868165493011475 seconds
Average featurization time: 0.77
(200, 19)
(160, 19)
(40, 19)
(200, 42)
(160, 42)
(40, 42)
Experiment time: 1.8905346393585205 seconds
Average featurization time: 0.03
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 4.839779376983643 seconds
Average featurization time: 0.77
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 4.923750400543213 seconds
Average featurization time: 0.78
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.268760442733765 seconds
Average featurization time: 0.78
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.199759244918823 seconds
Average featurization time: 0.77
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.29938530921936 seconds
Average featurization time: 0.78
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.274975299835205 seconds
Average featurization time: 0.78
(200, 42)
(160, 42)
(40, 42)
(200, 571)
(160, 571)
(40, 571)
Experiment time: 1.9856276512145996 seconds
Average featurization time: 0.03
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.057912588119507 seconds
Average featurization time: 0.78
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.154928207397461 seconds
Average featurization time: 0.79
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.231577634811401 seconds
Average featurization time: 0.78
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.181920766830444 seconds
Average featurization time: 0.77
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.296887636184692 seconds
Average featurization time: 0.79
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.259523868560791 seconds
Average featurization time: 0.78
(200, 571)
(160, 571)
(40, 571)
(200, 347)
(160, 347)
(40, 347)
Experiment time: 2.012345790863037 seconds
Average featurization time: 0.03
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.023024320602417 seconds
Average featurization time: 0.78
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.108036041259766 seconds
Average featurization time: 0.79
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.244540214538574 seconds
Average featurization time: 0.78
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.205528736114502 seconds
Average featurization time: 0.77
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.249536037445068 seconds
Average featurization time: 0.79
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.2748472690582275 seconds
Average featurization time: 0.78
(200, 347)
(160, 347)
(40, 347)
(200, 643)
(160, 643)
(40, 643)
Experiment time: 2.0011188983917236 seconds
Average featurization time: 0.03
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.0977349281311035 seconds
Average featurization time: 0.78
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.130184173583984 seconds
Average featurization time: 0.79
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.202197790145874 seconds
Average featurization time: 0.78
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.270749092102051 seconds
Average featurization time: 0.78
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.26352596282959 seconds
Average featurization time: 0.79
(200, 1024)
(160, 1024)
(40, 1024)
(200, 1024)
(160, 1024)
(40, 1024)
Experiment time: 5.317890644073486 seconds
Average featurization time: 0.79
(200, 643)
(160, 643)
(40, 643)
(200, 614)
(160, 614)
(40, 614)
Experiment time: 2.032585859298706 seconds
Average featurization time: 0.03
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.129095792770386 seconds
Average featurization time: 0.79
(200, 50)
(160, 50)
(40, 50)
(200, 50)
(160, 50)
(40, 50)
Experiment time: 5.092933893203735 seconds
Average featurization time: 0.79
